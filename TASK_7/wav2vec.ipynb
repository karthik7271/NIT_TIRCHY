{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install yt-dlp -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!yt-dlp https://youtu.be/zmf1Kujygt8 --format m4a -o \"/content/%(id)s.%(ext)s\"\n",
    "!whisper \"/content/zmf1Kujygt8.m4a\" --model small --language English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install gTTS\n",
    "!pip install SpeechRecognition\n",
    "!pip install pydub\n",
    "!pip install translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "from translate import Translator\n",
    "from gtts import gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(input_mp3, output_wav):\n",
    "    audio = AudioSegment.from_m4a(input_mp3)\n",
    "    audio.export(output_wav, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_m4a_to_wav(input_file, output_file):\n",
    "    # Load the .m4a file\n",
    "    audio = AudioSegment.from_file(input_file, format='m4a')\n",
    "    # Export as .wav\n",
    "    audio.export(output_file, format='wav')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def recognize_speech(audio_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "    try:\n",
    "        recognized_text = recognizer.recognize_google(audio_data)\n",
    "        return recognized_text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Speech recognition could not understand the audio\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Could not request results from Google's Speech Recognition API; {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def translate_text(text, target_language):\n",
    "    if text is not None:\n",
    "        translator = Translator(to_lang=target_language)\n",
    "        translation = translator.translate(text)\n",
    "        return translation\n",
    "    else:\n",
    "        return \"No text to translate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convert_text_to_speech(text, lang_code, output_path):\n",
    "    if text != \"No text to translate\":\n",
    "        tts = gTTS(text=text, lang=lang_code)\n",
    "        tts.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def speech_to_speech_pipeline(input_mp3, output_mp3, target_language='hi'):\n",
    "    # Step 1: Convert MP3 to WAV\n",
    "    wav_file = \"temp_speech.wav\"\n",
    "    convert_m4a_to_wav(input_mp3, wav_file)\n",
    "\n",
    "    # Step 2: Recognize Speech\n",
    "    recognized_text = recognize_speech(wav_file)\n",
    "    print(\"Recognized Speech:\")\n",
    "    print(recognized_text)\n",
    "\n",
    "    # Step 3: Translate Recognized Text\n",
    "    translated_text = translate_text(recognized_text, target_language)\n",
    "    print(\"Translated Text:\")\n",
    "    print(translated_text)\n",
    "\n",
    "    # Step 4: Convert Translated Text to Speech\n",
    "    convert_text_to_speech(translated_text, target_language, output_mp3)\n",
    "    audio = AudioSegment.from_mp3(output_mp3)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_audio_file = \"/kaggle/input/indicsuperb/kb_data_clean_m4a/hindi/valid/audio/844424930501806-229-f.m4a\" \n",
    "output_audio_file = \"translated_ta.mp3\"\n",
    "speech_to_speech_pipeline(input_audio_file, output_audio_file, target_language='ka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHISPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\", model=\"openai/whisper-base\", device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"facebook/voxpopuli\", \"it\", split=\"validation\", streaming=True)\n",
    "sample = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(sample[\"audio\"][\"array\"], rate=sample[\"audio\"][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def translate(audio):\n",
    "    outputs = pipe(audio, max_new_tokens=256, generate_kwargs={\"task\": \"translate\"})\n",
    "    return outputs[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "translate(sample[\"audio\"].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample[\"raw_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "vocoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def synthesise(text):\n",
    "    inputs = processor(text=text, return_tensors=\"pt\")\n",
    "    speech = model.generate_speech(\n",
    "        inputs[\"input_ids\"].to(device), speaker_embeddings.to(device), vocoder=vocoder\n",
    "    )\n",
    "    return speech.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "target_dtype = np.int16\n",
    "max_range = np.iinfo(target_dtype).max\n",
    "\n",
    "def speech_to_speech_translation(audio):\n",
    "    translated_text = translate(audio)\n",
    "    synthesised_speech = synthesise(translated_text)\n",
    "    synthesised_speech = (synthesised_speech.numpy() * max_range).astype(np.int16)\n",
    "    return 16000, synthesised_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sampling_rate, synthesised_speech = speech_to_speech_translation(\"/kaggle/input/indicsuperb/kb_data_clean_m4a/tamil/valid/audio/844424930305399-797-m.m4a\")\n",
    "Audio(synthesised_speech, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  AI4BHARAT (MACHINE TRANSLATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --force-reinstall --no-cache-dir numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from IndicTransToolkit.processor import IndicProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "src_lang, tgt_lang = \"hin_Deva\", \"kan_Knda\"\n",
    "model_name = \"ai4bharat/indictrans2-indic-indic-1B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True, \n",
    "    torch_dtype=torch.float16, \n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").to(DEVICE)\n",
    "\n",
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "input_sentences = [\n",
    "    \"जब मैं छोटा था, मैं हर रोज़ पार्क जाता था।\",\n",
    "    \"हमने पिछले सप्ताह एक नई फिल्म देखी जो कि बहुत प्रेरणादायक थी।\",\n",
    "    \"अगर तुम मुझे उस समय पास मिलते, तो हम बाहर खाना खाने चलते।\",\n",
    "    \"मेरे मित्र ने मुझे उसके जन्मदिन की पार्टी में बुलाया है, और मैं उसे एक तोहफा दूंगा।\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch = ip.preprocess_batch(\n",
    "    input_sentences,\n",
    "    src_lang=src_lang,\n",
    "    tgt_lang=tgt_lang,\n",
    ")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "inputs = tokenizer(\n",
    "    batch,\n",
    "    truncation=True,\n",
    "    padding=\"longest\",\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True,\n",
    ").to(DEVICE)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        use_cache=True,\n",
    "        min_length=0,\n",
    "        max_length=256,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=1,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generated_tokens = tokenizer.batch_decode(\n",
    "    generated_tokens,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=True,\n",
    ")\n",
    "\n",
    "translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences, translations):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI4BHARAT TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/huggingface/parler-tts.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from parler_tts import ParlerTTSForConditionalGeneration\n",
    "from transformers import AutoTokenizer\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ParlerTTSForConditionalGeneration.from_pretrained(\"ai4bharat/indic-parler-tts\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-parler-tts\")\n",
    "description_tokenizer = AutoTokenizer.from_pretrained(model.config.text_encoder._name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prompt = \"मेरे मित्र ने मुझे उसके जन्मदिन की पार्टी में बुलाया है, और मैं उसे एक तोहफा दूंगा।\"\n",
    "description = \"A calm, warm female voice with medium pitch and a steady speed.\"\n",
    "\n",
    "description_input_ids = description_tokenizer(description, return_tensors=\"pt\").to(device)\n",
    "prompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "generation = model.generate(input_ids=description_input_ids.input_ids, attention_mask=description_input_ids.attention_mask, prompt_input_ids=prompt_input_ids.input_ids, prompt_attention_mask=prompt_input_ids.attention_mask)\n",
    "audio_arr = generation.cpu().numpy().squeeze()\n",
    "sf.write(\"indic_hindi.wav\", audio_arr, model.config.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI4BHARAT STT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install onnxruntime\n",
    "# Install dependencies\n",
    "!pip install transformers torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:33:10.070142Z",
     "iopub.status.busy": "2025-05-19T07:33:10.069188Z",
     "iopub.status.idle": "2025-05-19T07:34:00.282634Z",
     "shell.execute_reply": "2025-05-19T07:34:00.281505Z",
     "shell.execute_reply.started": "2025-05-19T07:33:10.070106Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621d242eadf04571996046cb9a6df2cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 403 files:   0%|          | 0/403 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTC Transcription: \n",
      "RNNT Transcription: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoModel\n",
    "import torchaudio\n",
    "\n",
    "# Load model\n",
    "model = AutoModel.from_pretrained(\"ai4bharat/indic-conformer-600m-multilingual\", trust_remote_code=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Load audio (replace with your file)\n",
    "wav, sr = torchaudio.load(\"/kaggle/input/tamil-dataset-90/New-Recording.wav\")\n",
    "wav = torch.mean(wav, dim=0, keepdim=True)\n",
    "target_sr = 16000\n",
    "if sr != target_sr:\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sr)\n",
    "    wav = resampler(wav)\n",
    "\n",
    "# Transcribe (choose language code, e.g., \"hi\" for Hindi)\n",
    "transcription_ctc = model(wav.to(device), \"hi\", \"ctc\")\n",
    "print(\"CTC Transcription:\", transcription_ctc)\n",
    "transcription_rnnt = model(wav.to(device), \"hi\", \"rnnt\")\n",
    "print(\"RNNT Transcription:\", transcription_rnnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDIC SEAMLESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install torch torchaudio transformers datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T08:03:44.883135Z",
     "iopub.status.busy": "2025-05-19T08:03:44.882462Z",
     "iopub.status.idle": "2025-05-19T08:03:45.800850Z",
     "shell.execute_reply": "2025-05-19T08:03:45.800095Z",
     "shell.execute_reply.started": "2025-05-19T08:03:44.883107Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T08:03:45.803044Z",
     "iopub.status.busy": "2025-05-19T08:03:45.802504Z",
     "iopub.status.idle": "2025-05-19T08:05:04.028581Z",
     "shell.execute_reply": "2025-05-19T08:05:04.027952Z",
     "shell.execute_reply.started": "2025-05-19T08:03:45.803017Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 08:03:59.625472: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747641839.817068      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747641839.871395      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe69631602a46d1ad64fc028703146a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effb3dc5e2614fbb9a0f7dd28210c3f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/139k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32d2c721778454a87c8a9a7a19bf287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3bbf76cc10f44498bc49952cf8eaa56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.01G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbca9ed2b07a45beaa37cb75edb97d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae836aa69b243898a041d21dd03f3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abbe5d82af04f27b9410bd722ea61d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/9.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c0cac843384f319f0005c404e18642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/1.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6f6ec6cd5c43629641f65baf52125c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/19.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12bd581c59d48299b12a69d53cfc98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07fd5036a5746439a36241666204289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d16f41c822413e9bdc2c91a452325f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchaudio\n",
    "from transformers import SeamlessM4Tv2ForSpeechToText\n",
    "from transformers import SeamlessM4TTokenizer, SeamlessM4TFeatureExtractor\n",
    "\n",
    "model = SeamlessM4Tv2ForSpeechToText.from_pretrained(\"ai4bharat/indic-seamless\").to(\"cuda\")\n",
    "processor = SeamlessM4TFeatureExtractor.from_pretrained(\"ai4bharat/indic-seamless\")\n",
    "tokenizer = SeamlessM4TTokenizer.from_pretrained(\"ai4bharat/indic-seamless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T08:12:41.780825Z",
     "iopub.status.busy": "2025-05-19T08:12:41.780481Z",
     "iopub.status.idle": "2025-05-19T08:12:42.943781Z",
     "shell.execute_reply": "2025-05-19T08:12:42.942915Z",
     "shell.execute_reply.started": "2025-05-19T08:12:41.780803Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कुंडुई की आंखें आज़वार्क कड़िया के साथ कुछ संगीतमय रूप में हैं।\n"
     ]
    }
   ],
   "source": [
    "audio, orig_freq = torchaudio.load(\"/kaggle/input/indian-languages-audio-dataset/Indian_Languages_Audio_Dataset/Tamil/10192.mp3\")\n",
    "audio = torchaudio.functional.resample(audio, orig_freq=orig_freq, new_freq=16_000) \n",
    "audio_inputs = processor(audio, sampling_rate=16_000, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "text_out = model.generate(**audio_inputs, tgt_lang=\"hin\")[0].cpu().numpy().squeeze()\n",
    "print(tokenizer.decode(text_out, clean_up_tokenization_spaces=True, skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 134745,
     "sourceId": 323057,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3948432,
     "sourceId": 6871056,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7453665,
     "sourceId": 11861700,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7453685,
     "sourceId": 11861723,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
