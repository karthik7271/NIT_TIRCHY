{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":323057,"sourceType":"datasetVersion","datasetId":134745},{"sourceId":6871056,"sourceType":"datasetVersion","datasetId":3948432},{"sourceId":11861700,"sourceType":"datasetVersion","datasetId":7453665},{"sourceId":11861723,"sourceType":"datasetVersion","datasetId":7453685}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/openai/whisper.git -q -U","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install yt-dlp -q -U","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!yt-dlp https://youtu.be/zmf1Kujygt8 --format m4a -o \"/content/%(id)s.%(ext)s\"\n!whisper \"/content/zmf1Kujygt8.m4a\" --model small --language English","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LIBRARIES","metadata":{}},{"cell_type":"code","source":"!pip install gTTS\n!pip install SpeechRecognition\n!pip install pydub\n!pip install translate","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pydub import AudioSegment\nimport speech_recognition as sr\nfrom translate import Translator\nfrom gtts import gTTS","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def convert_mp3_to_wav(input_mp3, output_wav):\n    audio = AudioSegment.from_m4a(input_mp3)\n    audio.export(output_wav, format=\"wav\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pydub import AudioSegment\n\ndef convert_m4a_to_wav(input_file, output_file):\n    # Load the .m4a file\n    audio = AudioSegment.from_file(input_file, format='m4a')\n    # Export as .wav\n    audio.export(output_file, format='wav')\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def recognize_speech(audio_path):\n    recognizer = sr.Recognizer()\n    with sr.AudioFile(audio_path) as source:\n        audio_data = recognizer.record(source)\n    try:\n        recognized_text = recognizer.recognize_google(audio_data)\n        return recognized_text\n    except sr.UnknownValueError:\n        return \"Speech recognition could not understand the audio\"\n    except sr.RequestError as e:\n        return f\"Could not request results from Google's Speech Recognition API; {e}\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def translate_text(text, target_language):\n    if text is not None:\n        translator = Translator(to_lang=target_language)\n        translation = translator.translate(text)\n        return translation\n    else:\n        return \"No text to translate\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def convert_text_to_speech(text, lang_code, output_path):\n    if text != \"No text to translate\":\n        tts = gTTS(text=text, lang=lang_code)\n        tts.save(output_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def speech_to_speech_pipeline(input_mp3, output_mp3, target_language='hi'):\n    # Step 1: Convert MP3 to WAV\n    wav_file = \"temp_speech.wav\"\n    convert_m4a_to_wav(input_mp3, wav_file)\n\n    # Step 2: Recognize Speech\n    recognized_text = recognize_speech(wav_file)\n    print(\"Recognized Speech:\")\n    print(recognized_text)\n\n    # Step 3: Translate Recognized Text\n    translated_text = translate_text(recognized_text, target_language)\n    print(\"Translated Text:\")\n    print(translated_text)\n\n    # Step 4: Convert Translated Text to Speech\n    convert_text_to_speech(translated_text, target_language, output_mp3)\n    audio = AudioSegment.from_mp3(output_mp3)\n    return audio","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_audio_file = \"/kaggle/input/indicsuperb/kb_data_clean_m4a/hindi/valid/audio/844424930501806-229-f.m4a\" \noutput_audio_file = \"translated_ta.mp3\"\nspeech_to_speech_pipeline(input_audio_file, output_audio_file, target_language='ka')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# WHISPER","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import pipeline\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\npipe = pipeline(\n    \"automatic-speech-recognition\", model=\"openai/whisper-base\", device=device\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"facebook/voxpopuli\", \"it\", split=\"validation\", streaming=True)\nsample = next(iter(dataset))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import Audio\nAudio(sample[\"audio\"][\"array\"], rate=sample[\"audio\"][\"sampling_rate\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def translate(audio):\n    outputs = pipe(audio, max_new_tokens=256, generate_kwargs={\"task\": \"translate\"})\n    return outputs[\"text\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"translate(sample[\"audio\"].copy())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample[\"raw_text\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n\nprocessor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\nmodel = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\nvocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.to(device)\nvocoder.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\nspeaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def synthesise(text):\n    inputs = processor(text=text, return_tensors=\"pt\")\n    speech = model.generate_speech(\n        inputs[\"input_ids\"].to(device), speaker_embeddings.to(device), vocoder=vocoder\n    )\n    return speech.cpu()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\ntarget_dtype = np.int16\nmax_range = np.iinfo(target_dtype).max\n\ndef speech_to_speech_translation(audio):\n    translated_text = translate(audio)\n    synthesised_speech = synthesise(translated_text)\n    synthesised_speech = (synthesised_speech.numpy() * max_range).astype(np.int16)\n    return 16000, synthesised_speech","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sampling_rate, synthesised_speech = speech_to_speech_translation(\"/kaggle/input/indicsuperb/kb_data_clean_m4a/tamil/valid/audio/844424930305399-797-m.m4a\")\nAudio(synthesised_speech, rate=sampling_rate)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  AI4BHARAT (MACHINE TRANSLATION)","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade --force-reinstall --no-cache-dir numpy==1.26.4","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nfrom IndicTransToolkit.processor import IndicProcessor","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nsrc_lang, tgt_lang = \"hin_Deva\", \"kan_Knda\"\nmodel_name = \"ai4bharat/indictrans2-indic-indic-1B\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\n    model_name, \n    trust_remote_code=True, \n    torch_dtype=torch.float16, \n    attn_implementation=\"flash_attention_2\"\n).to(DEVICE)\n\nip = IndicProcessor(inference=True)\n\ninput_sentences = [\n    \"जब मैं छोटा था, मैं हर रोज़ पार्क जाता था।\",\n    \"हमने पिछले सप्ताह एक नई फिल्म देखी जो कि बहुत प्रेरणादायक थी।\",\n    \"अगर तुम मुझे उस समय पास मिलते, तो हम बाहर खाना खाने चलते।\",\n    \"मेरे मित्र ने मुझे उसके जन्मदिन की पार्टी में बुलाया है, और मैं उसे एक तोहफा दूंगा।\",\n]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch = ip.preprocess_batch(\n    input_sentences,\n    src_lang=src_lang,\n    tgt_lang=tgt_lang,\n)\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ninputs = tokenizer(\n    batch,\n    truncation=True,\n    padding=\"longest\",\n    return_tensors=\"pt\",\n    return_attention_mask=True,\n).to(DEVICE)\n\n\nwith torch.no_grad():\n    generated_tokens = model.generate(\n        **inputs,\n        use_cache=True,\n        min_length=0,\n        max_length=256,\n        num_beams=5,\n        num_return_sequences=1,\n    )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generated_tokens = tokenizer.batch_decode(\n    generated_tokens,\n    skip_special_tokens=True,\n    clean_up_tokenization_spaces=True,\n)\n\ntranslations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n\nfor input_sentence, translation in zip(input_sentences, translations):\n    print(f\"{src_lang}: {input_sentence}\")\n    print(f\"{tgt_lang}: {translation}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# AI4BHARAT TTS","metadata":{}},{"cell_type":"code","source":"! pip install git+https://github.com/huggingface/parler-tts.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom parler_tts import ParlerTTSForConditionalGeneration\nfrom transformers import AutoTokenizer\nimport soundfile as sf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = ParlerTTSForConditionalGeneration.from_pretrained(\"ai4bharat/indic-parler-tts\").to(device)\ntokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-parler-tts\")\ndescription_tokenizer = AutoTokenizer.from_pretrained(model.config.text_encoder._name_or_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = \"मेरे मित्र ने मुझे उसके जन्मदिन की पार्टी में बुलाया है, और मैं उसे एक तोहफा दूंगा।\"\ndescription = \"A calm, warm female voice with medium pitch and a steady speed.\"\n\ndescription_input_ids = description_tokenizer(description, return_tensors=\"pt\").to(device)\nprompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device)\n\ngeneration = model.generate(input_ids=description_input_ids.input_ids, attention_mask=description_input_ids.attention_mask, prompt_input_ids=prompt_input_ids.input_ids, prompt_attention_mask=prompt_input_ids.attention_mask)\naudio_arr = generation.cpu().numpy().squeeze()\nsf.write(\"indic_hindi.wav\", audio_arr, model.config.sampling_rate)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# AI4BHARAT STT","metadata":{}},{"cell_type":"code","source":"!pip install onnxruntime\n# Install dependencies\n!pip install transformers torchaudio","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport torch\nfrom transformers import AutoModel\nimport torchaudio\n\n# Load model\nmodel = AutoModel.from_pretrained(\"ai4bharat/indic-conformer-600m-multilingual\", trust_remote_code=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Load audio (replace with your file)\nwav, sr = torchaudio.load(\"/kaggle/input/tamil-dataset-90/New-Recording.wav\")\nwav = torch.mean(wav, dim=0, keepdim=True)\ntarget_sr = 16000\nif sr != target_sr:\n    resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sr)\n    wav = resampler(wav)\n\n# Transcribe (choose language code, e.g., \"hi\" for Hindi)\ntranscription_ctc = model(wav.to(device), \"hi\", \"ctc\")\nprint(\"CTC Transcription:\", transcription_ctc)\ntranscription_rnnt = model(wav.to(device), \"hi\", \"rnnt\")\nprint(\"RNNT Transcription:\", transcription_rnnt)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:33:10.069188Z","iopub.execute_input":"2025-05-19T07:33:10.070142Z","iopub.status.idle":"2025-05-19T07:34:00.282634Z","shell.execute_reply.started":"2025-05-19T07:33:10.070106Z","shell.execute_reply":"2025-05-19T07:34:00.281505Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Fetching 403 files:   0%|          | 0/403 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"621d242eadf04571996046cb9a6df2cd"}},"metadata":{}},{"name":"stdout","text":"CTC Transcription: \nRNNT Transcription: \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# INDIC SEAMLESS","metadata":{}},{"cell_type":"code","source":"pip install torch torchaudio transformers datasets\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:03:44.882462Z","iopub.execute_input":"2025-05-19T08:03:44.883135Z","iopub.status.idle":"2025-05-19T08:03:45.800850Z","shell.execute_reply.started":"2025-05-19T08:03:44.883107Z","shell.execute_reply":"2025-05-19T08:03:45.800095Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torchaudio\nfrom transformers import SeamlessM4Tv2ForSpeechToText\nfrom transformers import SeamlessM4TTokenizer, SeamlessM4TFeatureExtractor\n\nmodel = SeamlessM4Tv2ForSpeechToText.from_pretrained(\"ai4bharat/indic-seamless\").to(\"cuda\")\nprocessor = SeamlessM4TFeatureExtractor.from_pretrained(\"ai4bharat/indic-seamless\")\ntokenizer = SeamlessM4TTokenizer.from_pretrained(\"ai4bharat/indic-seamless\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:03:45.802504Z","iopub.execute_input":"2025-05-19T08:03:45.803044Z","iopub.status.idle":"2025-05-19T08:05:04.028581Z","shell.execute_reply.started":"2025-05-19T08:03:45.803017Z","shell.execute_reply":"2025-05-19T08:05:04.027952Z"}},"outputs":[{"name":"stderr","text":"2025-05-19 08:03:59.625472: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747641839.817068      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747641839.871395      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.76k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fe69631602a46d1ad64fc028703146a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/139k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"effb3dc5e2614fbb9a0f7dd28210c3f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e32d2c721778454a87c8a9a7a19bf287"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.01G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3bbf76cc10f44498bc49952cf8eaa56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbca9ed2b07a45beaa37cb75edb97d01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fae836aa69b243898a041d21dd03f3b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/9.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2abbe5d82af04f27b9410bd722ea61d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/1.78k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8c0cac843384f319f0005c404e18642"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/19.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd6f6ec6cd5c43629641f65baf52125c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.17M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e12bd581c59d48299b12a69d53cfc98a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.07k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f07fd5036a5746439a36241666204289"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81d16f41c822413e9bdc2c91a452325f"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"audio, orig_freq = torchaudio.load(\"/kaggle/input/indian-languages-audio-dataset/Indian_Languages_Audio_Dataset/Tamil/10192.mp3\")\naudio = torchaudio.functional.resample(audio, orig_freq=orig_freq, new_freq=16_000) \naudio_inputs = processor(audio, sampling_rate=16_000, return_tensors=\"pt\").to(\"cuda\")\n\ntext_out = model.generate(**audio_inputs, tgt_lang=\"hin\")[0].cpu().numpy().squeeze()\nprint(tokenizer.decode(text_out, clean_up_tokenization_spaces=True, skip_special_tokens=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:12:41.780481Z","iopub.execute_input":"2025-05-19T08:12:41.780825Z","iopub.status.idle":"2025-05-19T08:12:42.943781Z","shell.execute_reply.started":"2025-05-19T08:12:41.780803Z","shell.execute_reply":"2025-05-19T08:12:42.942915Z"}},"outputs":[{"name":"stdout","text":"कुंडुई की आंखें आज़वार्क कड़िया के साथ कुछ संगीतमय रूप में हैं।\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}